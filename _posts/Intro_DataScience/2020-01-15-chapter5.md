---
layout: post
title:  "数据科学导论💻 chapter5"
categories: Data_Science
permalink: :/categories/:day/:month:/year
---

# 数据科学导论💻

## **数据科学的应用**

本节回顾了数据科学已经或正在投入使用的不同应用。在阅读案例的时候，你需要考虑它与下列因素的关系（思考点什么🤔有助于你阅读，不然你会走神的）：

- 如何解释该应用的价值链。
- 该应用在生态系统中的角色是怎样的。
- 什么因素使得该应用成功。

麦肯锡全球研究所2011年关于大数据的经典报告可以在MGI的“大数据:创新、竞争和生产力的下一个前沿”中找到。 [(下载完整报告PDF/EPUB/MOBI)](https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/big-data-the-next-frontier-for-innovation)

选择以下感兴趣的应用领域。

- 健康:39-51页
- 政府:54 - 63页
- 零售:64 - 75页
- 定位技术:85-95页

### NIST大数据工作组提出的分析框架

NIST使用一套标准来组织他们的分析，我们将转换成我们自己的术语。他们的标准可以在[NIST大数据互操作框架:第3卷](https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1500-3.pdf)中找到。

- 数据源（data source）:数据来自何处?
- 体量（volume）:有多少数据?
- 速度（velocity）:它如何随时间变化?

- 多样性（variety）:有哪些不同类型的数据?
- 软件（software）:在各个步骤中使用的主要软件是什么?
- 分析（analytics）:需要进行哪些类型的分析?转变:什么样的争吵会发生?

- 数据消费者（data consumer）:运营化，结果会怎样?
- 安全性和隐私（Security & Privacy:）:治理的各个方面
- 生命周期管理（Lifecycle Management）:如何管理治理?

因此，我们可以看到NIST框架描述了来自标准价值链的主要步骤、数据的一些关键维度(我们将在下一模块中详细介绍)和所使用的软件。

## **数据类型和存储**

### 何为大数据？

显然，“大数据”是一个含义丰富的术语。多大才算大? 我们需要定义数据，已经有人提出了数据的3v，4v甚至7v去定义解释数据的维度。

Eileen McNulty在数据分类新闻门户网站上发表的《理解大数据:七个V》(1100字，5分钟)[传送门🚪](https://dataconomy.com/2014/05/seven-vs-big-data/)

Mark van Rijmenam在Datafloq门户网站上发表了《为什么3V足以描述大数据》(1300字，6分钟)[传送门🚪](https://datafloq.com/read/3vs-sufficient-describe-big-data/166)

业界还有人把大数据的基本特征从4V扩展到了11V，包括价值密度低（Value）、可视化（Visualization）、有效性（Validity）等。在此，仅介绍最常用大数据的四个特征4V:

- **V**olume：数据量巨大
- **V**ariety：数据种类繁多
- **V**elocity：处理速度快
- **V**eracity：真实不确定性

![The four V’s of Big data](https://www.ibmbigdatahub.com/sites/default/files/styles/xlarge-scaled/public/infographic_image/4-Vs-of-big-data.jpg?itok=4syrvSLX)

### 数据类型

#### 元数据（Metadata）

在计算机科学中，我们讨论数据格式，它可以是原始文件或磁盘格式。但是在这个层次之上，我们需要的是存储信息的格式，而不是单个字母或浮点数。为此，存在元数据，元数据通常被定义为关于数据的数据。

> 它是“描述、解释、定位或以其他方式使检索、使用或管理信息资源更容易的结构化信息”。
>
> Metadata is structured information that describes, explains, locates, or otherwise makes it easier to retrieve, use or manage an information resource.

[Wikipedia](https://en.wikipedia.org/wiki/Metadata_standard#Metadata)提供了三种类型的元数据。

- 描述性元数据（Descriptive）：通过标题、作者和摘要等元素描述用于标识和检索的信息资源。
- 结构化元数据（Structural）：通过元素(例如到其他组件的链接)记录对象内部和对象之间的关系(例如，如何将页面放在一起形成章节)。
- 管理元数据（Administrative）：有助于通过版本号、归档日期和其他技术信息等元素管理信息资源，以便进行文件管理、权限管理和保存。

#### 其他相关术语

- 机器可读的数据（Machine-readable data）是一种格式可以被计算机理解的数据(或元数据)。
- 标记语言（Markup language）是一种对文档进行注释的系统，其语法与文本不同。
- 数字容器/包装器（Digital-container/wrapper) format）格式是一种文件格式，其规范描述了数据和元数据的不同元素如何在计算机文件中共存。

容器在多媒体应用程序中经常使用。我们可以说，标记语言是通过注释完成的一种描述性元数据。它在嵌入式文档的编程语言中也很流行。

### **增长的法律**

从技术的角度来理解大数据是不可避免的，而且只会越来越大，这里有四个所谓的技术定律，讨论了增长的必然性。这些都是基于观察的预测，但大多数都经受住了时间的考验。

#### 摩尔定律Moore's Law

> Moore's law states that the transistors in a dense integrated circuit double approximately every two years(starting from 1975).
>

最著名的增长规律,摩尔定律,从英特尔创始人戈登•摩尔指出:在计算硬件的历史,在高密度集成电路的晶体管数量翻了一倍。

#### 库米定律Koomey's Law

> Koomey's law states that the energies efficiency doubles roughly every 18 months.

摩尔定律的一个推论，库米定律，是关于能源消耗的:库米定律的含义是，固定计算负载所需的电池数量将每十年下降100倍。这确实意味着物联网的必然性，就我们的目的而言，比数据科学类型的分析方法将越来越多地为普通大众所使用，计算成本也越来越低(就能力而言)。

#### 贝尔定律Bell's Law

> Roughly every decade a new, lower-priced computer class forms based on a new programming platform, network, and interface resulting in new usage and the establishment of a new industry.

基于摩尔定律(同时也是库米定律)，计算梦想家戈丹·贝尔提出了贝尔定律，该定律认为每隔十年左右，就会出现一种新的计算机系统，从根本上改变我们做生意的方式。最近沿着这条路线的“类”有移动计算、云计算和物联网。对于数据科学来说，每一个都是至关重要的。这些新的类为收集、存储、处理和分发数据开辟了全新的途径。

#### 齐默尔曼定律Zimmerman's Law

> Zimmerman's Law states that the natural flow of technology tends to move in the direction of making surveillance easier, and the ability of computers to track us doubles every eighteen months.

齐默尔曼是世界上使用最广泛的电子邮件加密软件Pretty Good Privacy (PGP)的创始人。齐默尔曼(Zimmerman)在自己的博客中阐述了他的定律：技术的自然流动趋向于使监控变得更容易，计算机跟踪我们的能力每18个月就会增加一倍。因此，隐私随着存储和跟踪数据能力的增强而减少。

### 数据的存储

#### 亟待改变的传统数据存储范式

传统上，企业事务之类的业务数据以文件的形式存储在文件系统中。最初，数据可以以文本文件或二进制形式存储，并按顺序处理。当数据变得更大、更普遍时，就需要一种标准化的方式来存储和访问数据。这导致了关系数据库管理系统(RDBMS)的发明。RDBMS使用描述数据的相关模式存储数据，并允许通过标准化结构化查询语言(SQL)访问数据。 

然而，最近这个范式已经碰到了几堵墙：

- RDBMS不擅长存储非结构化（unstructured）或半结构化（semi-structured）数据。

- Rigid schema意味着RDBMS的设置和维护非常昂贵。

- 需要提前知道你的schema，这对于数据科学过程来说并不理想。

- 更改schema既困难又耗时。

- RDBMS被设计成运行在一台计算机上，所以处理数据很慢。

业务在不断变化的环境中运行:这个环境反映在数据库模式中，因此必须不断变化。组织拥有的数据越多，schema适应的任务就越繁重。在大数据的世界里，维护一个经典的RDBMS的努力已经变得难以管理。一种解决方案是less-schema的NoSQL数据库。

企业正在转向数据驱动的决策制定，需要在大量数据上运行复杂的分析查询，这是SQL设计者从未设想过的使用模式。为特定类型的复杂分析查询优化的NoSQL数据库管理方法的一个例子是graph数据库。

现代商业需要更快地获得洞察力并实时地对其采取行动。先存储后查询”的方法无法满足这种需要，必须开发工具来实时地处理数据。这种类型的数据称为流（stream）。这就产生了流分析（streaming analysis）。 

#### 新型数据库

因此，随着不同数据库类型的发展，如NoSQL和graph数据库，RDBMS本身也必须发展。最初这些设计是为了在大型主机上工作，随着存储需求的增加，总是扩大机器的存储和处理能力的解决方案不再可行。可伸缩系统（scalable）和大型系统之间是有区别的。可伸缩的系统可以随着需求而扩展。

大多数组织采取的缓解日益增长的存储影响的第一步是根据数据类型将其分离，将其存储在大量的RDBMS中，通常每个部门一个RDBMS。今天,这个临时的解决方案成为组织利用的数据路上最大的绊脚石，因为它意味着孤立，数据存储方法在各个部门不一致。数据科学家们花费了大量的时间“整理”数据。

解决数据竖井问题的一个更现代的解决方案是使用分布式数据库。

通过正确地组合分布式数据库和软件工具，可以实现分布式分析。这种分析不需要将数据移出数据库进行分析，称为数据库内分析（in-database analytics）。

对于分布式存储，可以使用Hadoop的基于map - reduce的生态系统，也可以只使用Hadoop的HDFS。Spark提供了自己的工具生态系统(Spark SQL用于关系数据，Spark流用于流数据，MLlib用于机器学习，GraphX用于图形分析)，独立于Hadoop生态系统。今天，用户希望他们的数据不仅是分布式的，而且可以在云中分布。尽管在这个领域有主要的趋势和明显的趋同，但必须注意的是，每个现有的平台都有局限性，不适合特定的业务。例如，尽管Hadoop有时被认为是大数据的同义词，但最初推出Map-Reduce的公司谷歌就不使用它。