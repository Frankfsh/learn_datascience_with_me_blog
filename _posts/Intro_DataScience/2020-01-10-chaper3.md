---
layout: post
title:  "数据科学导论 chapter3"
categories: Data_Science
permalink: :/categories/:day/:month:/year
---

# 数据科学导论💻

## 数据资源、标准、工具和流程

### 数据资源

本节给出了一些创造性地使用数据、数据融合、开放数据和行业需要的通用标准的案例。在数据科学领域，创造力的一个主要来源是思考组合现有数据集或生成新数据集以产生“价值”的不同方式。

#### 开放数据（open data）

开放数据的理念是，一些数据应该免费提供给每个人使用和按他们的意愿重新发布，不受版权、专利或其他控制机制的限制。开放数据也可以是linked open data。开放数据最重要的形式之一是开放政府数据(open government data, OGD)，它是由执政的政府机构创建的一种开放数据形式。公开政府数据的重要性来自于它是公民日常生活的一部分，甚至是那些看似远离政府的日常事务。GovHack是一个基于澳大利亚和新西兰政府数据的黑客马拉松。GovHack在其网站上自述：GovHack是一个将人们聚集在一起用公开的政府数据进行创新的活动。

- 开放数据帮助企业提高生产力，创造新的产品和服务，尤其是帮助消费者。

- 公开数据带来了新的风险，包括对声誉的威胁和机密信息控制权的丧失。

- 作为公开数据的来源和监管者，政府可以发挥核心作用。

- 开放数据支持公众对政策的理解，提高公民的参与和参与。

- 开放数据还支持在公共和私人环境中的跨部门协作，例如灾难响应和教育。

#### 数据融合（data fusion）

微软公司的埃里克·霍维茨(Eric Horvitz)和他的团队使用了两种药物，他们对测试患者同时服用这两种药物是否会导致高血糖很感兴趣。除了医院获取的数据外，他们还将来自网络查询（web query）的匿名行为数据转换为大规模公共卫生的传感器，包括识别药物的不良影响和了解人群中的疾病。药物相互作用问题的“真实”数据可从AERS获得。而网络查询被用作“代理数据（proxy data）”，需要分析，推导和校准才能获得我们想要的信息。最后将代理数据与真实数据融合可以提供更好的分析结果。

#### 数据降噪（data wrangling）



### 数据标准

#### 什么是标准

大多数技术的成熟标志是标准的出现。标准用于使能够、促进、度量，也许还用于管理在广泛的社区范围内对该技术的使用。标准化增加了技术的独立使用和比较评价。[“Raising the Standard in the Big Data Analytics Profession” by Dr. Kirk Bourne (blog, 1100 words, 6 mins)](https://mapr.com/blog/raising-standard-big-data-analytics-profession/)

标准可能与过程（processes）相关：

- 业务过程改进(如Six Sigma)
- 软件工程(如CMM, the capability maturity model)
- 质量管理(如ISO 9000/9001)
- 教育传递(如Common Core)
- 数据挖掘(如 [CRISP-DM](http://en.wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining)，the Cross Industry Standard Process for Data Mining)

标准也可以适用于行为规范(如在军事、医疗、会计和法律行业)。

其他标准适用于数码内容，包括:

- 可互操作的数据交换(例如GIS、CDF或基于xml的数据标准)
- 数据格式(例如ASCII或IEEE 754)
- 图像格式(例如GIF或JPEG)
- 元数据编码标准(如医疗行业的ICD-10，或文化、研究和信息工件的 [Dublin Core](http://dublincore.org/));
- 共享模型标准(如 [PMML](http://en.wikipedia.org/wiki/Predictive_Model_Markup_Language)，the predictive model markup languag)。

标准是无处不在的。

#### 半结构化数据（semi-structured）的数据格式标准

- XML
- RDF
- JASON

#### 数据API和软件即服务(SaaS)

**开源软件**

**预测模型**

预测模型标记语言(PMML)是用XML开发的表示预测模型的标准。

### 数据工具

| Software     | 2018 % share | % change 2018 vs 2017 |
| ------------ | ------------ | --------------------- |
| Python       | 65.6%        | 11%                   |
| RapidMiner   | 52.7%        | 65%                   |
| R            | 48.5%        | -14%                  |
| SQL          | 39.6%        | 1%                    |
| Excel        | 39.1%        | 24%                   |
| Anaconda     | 33.4%        | 37%                   |
| Tensorflow   | 29.9%        | 32%                   |
| Tableau      | 26.4%        | 21%                   |
| scikit-learn | 24.4%        | 11%                   |
| Keras        | 22.2%        | 108%                  |



### 数据和标准案例分析

- wikidata
- TextRazor
- PubMed & MEDLINE
- ACM
- Patents database
- DBLP
- DCMI
- EventRegistry and NewsML
- Data.gov and NYC Open Data
- AURIN
- BioGrid Australia

### 数据分析的流程

在这一节中，我们将介绍学习的不同统计理论。我们不是在追求统计学或机器学习中的标准理论。我们将学习一种通用的图形化建模语言，并在不做任何数学运算的情况下研究机器学习理论的思想。诚然，我们会考虑一些数学问题，但会尽可能少地考虑。统计学习的一些主要原则很容易理解，这可以通过观察学习中的动作、曲线和曲线来实现。

#### 图形化的模型

我们要看的第一个理论是基于图形模型的。并不是所有的学习问题都可以用图形模型有效地表示出来，但是有很多是这样的。

影响图（Influence diagram）

[朱迪娅·珀尔，《智能系统中的概率推理》，1988年](https://www.sciencedirect.com/topics/computer-science/influence-diagram)

影响图是有向无环图，有三种类型的节点—决策节点、机会节点和值节点。决策节点以正方形表示，表示决策者可用的选择。随机节点表示为圆形，表示随机变量(或不确定量)。最后，以菱形表示的值节点表示要最大化的目标(或效用)。

图中的弧有不同的含义，基于它们的目的地。指向效用节点和机会节点的弧表示概率或功能依赖，就像贝叶斯网络中的弧一样。它们不一定意味着因果关系或时间优先，尽管在实践中它们经常这样做。进入决策节点的弧意味着时间优先，并且是信息性的。，它们显示了决策者在做出决策之前应该知道哪些变量。

还有一些情况，影响图中有四种节点。它们通常用矩形表示决策；带有椭圆形或圆形表示偶然事件或不确定性；用圆角矩形表示计算或固定输入输出；用三角形表示计算结果或值。

##### 贝叶斯网络（Bayesian network）

贝叶斯网络（Bayesian Networks）也被称为信念网络（Belif Networks）或者因果网络（Causal Networks），是描述数据变量之间依赖关系的一种图形模式，是一种用来进行推理的模型。

贝叶斯网的网络结构是一个有向无环图（Directed Acyclic Graph），其中每个结点代表一个属性或者数据变量，结点间的弧代表属性（数据变量） 间的概率依赖关系。一条弧由一个属性（数据变量）A指向另外一个属性（数据变量）B说明属性A的取值可以对属性B的取值产生影响，由于是有向无环图，A、B间不会出现有向回路。在贝叶斯网当中，直接的原因结点（弧尾）A叫做其结果结点（弧头）B的双亲结点（parents），B叫做A的孩子结点（children）。如果从一个结点X有一条有向通路指向Y，则称结点X为结点Y的祖先（ancestor），同时称结点Y为结点X的后代（descendent）。

##### 因果关系图（Casual loop）

##### 故障树（Fault tree）

##### 决策树（Decison tree）

##### 关系

当从影响图中移除决策和目标节点时，它们通常被称为贝叶斯网络。相关的模型是[因果循环图](https://en.wikipedia.org/wiki/Causal_loop_diagram)，它是隐含时间的影响图。因果循环图在商业和医学建模中很流行，以显示反馈效应。故障树图用于[故障树分析](https://en.wikipedia.org/wiki/Fault_tree_analysis)和[根源分析](https://en.wikipedia.org/wiki/Fault_tree_analysis)。故障树图是贝叶斯网络的布尔抽象，广泛用于大规模网络故障诊断。

#### 划分（Segmentation）

#### 时间序列预测

动态模型是一类特别重要和广泛的模型。在排序很重要的情况下，例如对于时间上发生的事情，可以使用这些方法。流数据通常来自这个上下文。医院的病人监控、学生在线学习环境(如mooc)的数据，以及通过复杂网站的互联网浏览行为，通常都是用动态模型建模的。

最简单的动态模型的数据以时间序列(一阶)的形式表示。一阶的时间序列预测其表示预测的下一个值是基于同序列中前一个值，也就是valuei变量由valuei-1变量预测。而高阶的时间序列预测基于不止一个之前的数据。训练数据包含顺序。例如在三阶时间序列里，valuei变量也可以由valuei-1, valuei-2, valuei-3变量来预测。

下一个层次的复杂性是引入潜在变量。我们大多数人手机里的GPS设备大概都有GPS定位图。其工作原理如下。GPS设备使用三个卫星信号来估计当前位置，通常精确到5米左右。这个数字表示我们不知道我们当前的位置，只能使用GPS来测量。但是我们也可以使用先前的估计位置来估计我们当前的位置，可能由于移动而发生的位置上的一个小的未知的变化。locationi变量是由locationi - 1估计的同时考虑gpsi变量。

### 学习理论导论

在这一节中，以直观的方式介绍了学习理论的一些经典结果。在科学或商业问题分析中，你可能有大量的数据。如果有足够的预算，您可能会获得更多的数据。但什么是潜在的“真相”。在物理学中，我们可以把牛顿物理学看作是物理学的一个模型，但我们知道它只是一个模型，并不是世界的真实反映(显然它更复杂)。在医学上，我们被告知孕妇应该服用特定的维生素或避免服用特定的药物，医生可能知道负面影响背后的一般机制，但影响后续影响程度的确切剂量通常是未知的。所有这些隐藏的细节都被称为“真相”。

我们对“真相”的关注是当我们做出新的预测，或者采取行动并等待结果(成本或价值)的时候。我们永远不可能做到完美，但我们希望尽可能做到最好。“真实”模型是一种进行概率评估的模型，我们可以据此做出预测，并在给定的环境下采取尽可能好的行动。一些例子:

对于一个无偏的六面骰子，“真”模型使六种结果的概率相等。

当然，总会有例外和挑战(如果风起了，如果经济变化了，等等)。然而，在大多数情况下，我们不知道“真相”，所以它通常是一些理想主义的未知作为一个参考点，但永远无法衡量。

#### 评估质量

预测的评估可以用许多不同的方法来衡量。如果预测的价值是真实的价值，那么评估和度量质量的一种方法就是使用“损失函数”，一种函数在如果预测是完美的时候应该返回零，否则是正的。预测与真实距离是递增函数。距离越远(或“误差”)，损失越大。在损失函数图中给出了几种常用的数学损失函数图。

#### 收敛性和样本容量

让我们用曲线拟合这个简单的概念来研究一下这个想法，它有时被称为回归。

其工作原理如下:在二维平面上给出一组数据点，数据以(X,Y)对的形式存在。图中所示为简单回归。



在图中，数据用蓝点绘制，这是“训练集”。我们的回归算法，细节不是很重要，假设我们有一个，根据训练集作为输入对“真”行进行估计。它估计它遵循绿色曲线。现在你可能认为你可以做得更好，也许你可以。例如，蓝色曲线在x=0附近的上升似乎是错误的。但是，这是我们的算法自动生成的。


 现在让我们考虑一下当我们增加训练集时会发生什么。这种情况在一个不断增长的样本的图回归中显示出来。



所以我们有一条蓝色的“真”线，两条灰色和黑色的估计线。注意:黑线通常比灰线更近。这条灰色的线在情节的左半部分真的很糟糕。这60个额外的数据点使黑线更适合。这就是学习。

现在让我们扩展相同的过程。我们将对一个逐渐增大的样本进行许多不同的回归。但所有这些情节都会变得相当混乱。因此，我们将提取适合的一个数字，均方误差(MSE)作为观测值。



在图中，我们可以看到四种不同情况下的均方误差。在每种情况下，数据集从50个样本点开始，逐渐增加到1000个样本点。你可以看到MSE的值一开始会跳来跳去，然后逐渐稳定下来。这种最初的不稳定行为是随机性的结果。

有时会看到一些不寻常的数据点(带有很大的噪声)，一开始它们可能会产生不好的影响。还要注意，最小值不是0 !它永远不会得到零误差拟合。对于某些问题，从长远来看完全的零误差拟合是可能的，但通常不是。在这种情况下，零误差从长远来看是不可能的，因为我们试图拟合一个10阶多项式，而“真”函数是超越函数。

当训练集变得非常大时，误差最小，这一事实被称为收敛。收敛速度是收敛发生的速度(以训练集的大小来衡量)。

#### 过拟合和欠拟合

考虑与上述回归拟合相同的情况。现在我们可以使用许多不同的模型来适应这30个点。下图是不同阶多项式的拟合，展示了将3阶、6阶、12阶和25阶多项式拟合到30个数据点时会发生什么。



大家可以看到，用红色表示的三阶多项式，没有足够的灵活性来拟合这个波形曲线。12阶多项式，紫色的，差不多了，但在极端情况下会有问题，25阶多项式，嗯，很疯狂。它有太多的自由度，所以包括了各种各样的疯狂的峰值，试图非常接近地拟合数据，在某些情况下，几乎完全吻合。根据这些描述，我们认为3阶多项式对数据拟合不足，25阶多项式对数据拟合过度。欠拟合和过拟合是我们对特定训练集和模型的描述。

这里的基本问题是我们应该在我们的模型中使用什么样的复杂性。如果我们有太多的复杂性，那么这个模型就有能力扭曲和弯曲任意类型的数据。这是一个低偏差模型。因此，如果没有足够大的数据来抵消这种影响，它将对未来的数据做出糟糕的预测。如果我们的复杂性太小，那么模型就不能很好地拟合数据，因此也应该对未来的数据做出糟糕的预测。这是一个高偏差模型。这些区别用偏倚-方差模型图表示。



注:在偏倚-方差模型图中，高偏置情况下训练集误差与“真值”相差不大，而小偏置情况下训练集误差与“真值”相差较大。小偏差模型需要较少的数据来拟合，因为模型的自由度较小。因此，他们报告的训练集错误更接近事实。

#### 训练集与测试集

在上述小节中，我们考虑了过拟合与欠拟合的问题。在学习中，我们总是需要更多的数据。我们的训练集越大，我们应该能够建立的模型就越精确。然而，我们也面临着试图防止过拟合的问题。我们想知道我们是否过度拟合。一种方法是保留一个测试集。我们保留一部分原始的、完整的数据集，并间歇地使用它来估计我们拥有的“真正的”错误。然而，这样做，我们也损害了我们的训练，因为我们有更少的数据来训练。

#### 信号与噪声

在图像处理和相关领域，人们谈论信号与噪声。信号是你想要通过“通道”进行交流的图像或视频，例如，通过无线电波或互联网。噪声是不需要的工件，可能是由于量化，瞬态电涌，通信错误，等等。

 我们的问题中的噪声可能是由于测量误差造成的，也可能反映了域本身的不确定性。例如，如果你在舌下测量你的体温，如果你身体健康，你期望的值是36.8±0.4。±0.4是辅助效应:时间、天气、活动量等。这些是测量中的不确定性。大概±0。2才是真正的测量误差，这么小的温度计。如果以分钟为单位计算你开车穿过市区去上班的时间，那么你有一个平均旅行时间，但是这个时间会因天气、城里的重大事件、道路工程等而变化很大，这也是不确定性，而不是真正的测量误差。然而，当我们收集数据并在图上绘制值时，我们并不知道不确定性背后的细节，因此很难将它们与噪声区分开。所以，我们经常用噪音这个词来表示所有这些无法测量的不确定性的影响。

#### 相关性(Correlation)和因果关系(causation)

相关性是变量之间的统计关联。这意味着观测到的值在某种程度上是相关的。例如:“病人长期吸烟”和“病人肺癌”是相关的。因果关系在很多情况下是隐藏的。长期以来，人们并不知道吸烟会导致癌症，因为这种影响的机理是复杂的生物学，只有极少数人知道。在这种情况下，我们可以很容易地测量吸烟和癌症之间的相关性，但吸烟会导致癌症吗?也许那些容易对吸烟上瘾的人有一种基因，这种基因也使他们容易患上肺癌。

一种公认的衡量因果关系的方法是干预。非正式地说，其基本思想如下:

为了检验A是否导致B，我们保持其他变量不变，然后强制A在一个观察的总体中有一个特定的值，然后观察B。如果在这种情况下，A与B相关，那么A导致B，是因果关系。

这里的干预是强迫A具有一定的行为。这种干预的概念是医学临床试验背后的基本理念。在临床试验中，受试者被分成两组，一组接受“治疗”，另一组不接受安慰剂。在这种情况下，通过干预，我们用相关性来检验因果关系。

然而，没有干预行为，相关性并不意味着因果关系。

穿鞋睡觉和醒来头痛有很强的相关性。因此，穿鞋睡觉会引起头痛。

上面的例子犯了“相关-隐含-因果关系”的谬误（correlation-implies-causation fallacy），因为它过早地得出结论:穿鞋睡觉会引起头痛。一个更合理的解释是，两者都是由第三个因素引起的，在这个例子中是醉酒后上床，这就产生了相关性。所以结论是错误的。

#### 无监督学习

#### 监督学习

弱监督学习

半监督学习

处理缺失值

#### 集成学习

#### 没有免费的午餐定理

在学习的过程中，Wolpert和McCready通过他们的no free lunch定理(维基百科)形成了“天下没有免费的午餐”的观点。这些定理被称为NFL定理，是技术性的，很难用非正式的方式精确地表述。但是他们使用的合理解释如下:

我们将相关的结果称为NFL定理，因为它们表明，如果一个算法在某类问题上表现良好，那么它必然会在所有剩余问题集上付出性能下降的代价。


 所以如果一个学习算法a在某些问题上做得很好，与其他问题相比，那么一定存在一个学习算法B在其他问题上比a做得更好。换句话说，没有一种算法可以在所有的学习场景中都表现良好。这是一个理论结果。

例如：

朴素贝叶斯分类在数据集较小的文本分类中表现良好

线性支持向量机在文本分类方面表现良好。